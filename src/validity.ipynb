{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a46f9cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VLM CLIENT TEST\n",
      "================================================================================\n",
      "✓ Config loaded\n",
      "✓ API key found (sk-or-v1-c...)\n",
      "\n",
      "Phase 1 Model: x-ai/grok-4.1-fast\n",
      "Phase 2 Model: x-ai/grok-code-fast-1\n",
      "\n",
      "================================================================================\n",
      "AVAILABLE X-AI/GROK MODELS ON OPENROUTER\n",
      "================================================================================\n",
      "  • x-ai/grok-3\n",
      "  • x-ai/grok-3-beta\n",
      "  • x-ai/grok-3-mini\n",
      "  • x-ai/grok-3-mini-beta\n",
      "  • x-ai/grok-4\n",
      "  • x-ai/grok-4-fast\n",
      "  • x-ai/grok-4.1-fast\n",
      "  • x-ai/grok-code-fast-1\n",
      "\n",
      "================================================================================\n",
      "TESTING PHASE 1 MODEL\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Phase 1 model works!\n",
      "  Response (13 chars): Phase 1 works\n",
      "\n",
      "================================================================================\n",
      "TESTING PHASE 2 MODEL\n",
      "================================================================================\n",
      "✓ Phase 2 model works!\n",
      "  Response (13 chars): Phase 2 works\n",
      "\n",
      "================================================================================\n",
      "TEST COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Simple VLM Client Test - Jupyter Notebook\n",
    "# Test if your models work with OpenRouter\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "def load_config(config_path='../config/config.yaml'):\n",
    "    \"\"\"Load YAML config\"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def test_openrouter_model(model_name, api_key, test_prompt=\"Say 'hello'\"):\n",
    "    \"\"\"\n",
    "    Test if a model works on OpenRouter\n",
    "    Returns: (success: bool, response: str, error: str)\n",
    "    \"\"\"\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": test_prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 100\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            content = result['choices'][0]['message']['content']\n",
    "            return True, content, None\n",
    "        else:\n",
    "            error_msg = f\"HTTP {response.status_code}: {response.text}\"\n",
    "            return False, None, error_msg\n",
    "            \n",
    "    except Exception as e:\n",
    "        return False, None, str(e)\n",
    "\n",
    "def list_available_models(api_key):\n",
    "    \"\"\"List all available models on OpenRouter\"\"\"\n",
    "    url = \"https://openrouter.ai/api/v1/models\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            models = response.json()['data']\n",
    "            xai_models = [m['id'] for m in models if 'x-ai' in m['id'] or 'grok' in m['id'].lower()]\n",
    "            return xai_models\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# ============================================================================\n",
    "# RUN TESTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VLM CLIENT TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Load config\n",
    "try:\n",
    "    config = load_config()\n",
    "    print(\"✓ Config loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Config loading failed: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2. Get API key\n",
    "api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"✗ OPENROUTER_API_KEY not found in environment\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"✓ API key found ({api_key[:10]}...)\")\n",
    "\n",
    "# 3. Extract models from config\n",
    "phase1_model = config['vlm_config']['phase1']['model']\n",
    "phase2_model = config['vlm_config']['phase2']['model']\n",
    "\n",
    "print(f\"\\nPhase 1 Model: {phase1_model}\")\n",
    "print(f\"Phase 2 Model: {phase2_model}\")\n",
    "\n",
    "# 4. List available xAI/Grok models\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AVAILABLE X-AI/GROK MODELS ON OPENROUTER\")\n",
    "print(\"=\"*80)\n",
    "available = list_available_models(api_key)\n",
    "if available:\n",
    "    for model in sorted(available):\n",
    "        print(f\"  • {model}\")\n",
    "else:\n",
    "    print(\"  (Could not fetch model list)\")\n",
    "\n",
    "# 5. Test Phase 1 model\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TESTING PHASE 1 MODEL\")\n",
    "print(\"=\"*80)\n",
    "success, response, error = test_openrouter_model(\n",
    "    phase1_model, \n",
    "    api_key, \n",
    "    \"Say exactly: 'Phase 1 works'\"\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(f\"✓ Phase 1 model works!\")\n",
    "    print(f\"  Response ({len(response)} chars): {response}\")\n",
    "else:\n",
    "    print(f\"✗ Phase 1 model FAILED\")\n",
    "    print(f\"  Error: {error}\")\n",
    "\n",
    "# 6. Test Phase 2 model\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TESTING PHASE 2 MODEL\")\n",
    "print(\"=\"*80)\n",
    "success, response, error = test_openrouter_model(\n",
    "    phase2_model, \n",
    "    api_key, \n",
    "    \"Say exactly: 'Phase 2 works'\"\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(f\"✓ Phase 2 model works!\")\n",
    "    print(f\"  Response ({len(response)} chars): {response}\")\n",
    "else:\n",
    "    print(f\"✗ Phase 2 model FAILED\")\n",
    "    print(f\"  Error: {error}\")\n",
    "    \n",
    "# 7. Suggest alternative if Phase 2 failed\n",
    "if not success:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SUGGESTED FIX\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Your Phase 2 model '{phase2_model}' doesn't exist.\")\n",
    "    print(f\"\\nTry one of these instead:\")\n",
    "    print(f\"  • x-ai/grok-4.1-fast  (recommended)\")\n",
    "    print(f\"  • x-ai/grok-4-fast\")\n",
    "    print(f\"  • x-ai/grok-beta\")\n",
    "    \n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TEST COMPLETE\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d43a341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING WITH REASONING PARAMETER\n",
      "================================================================================\n",
      "\n",
      "With reasoning parameter:\n",
      "  Status: 200\n",
      "  Response: \n",
      "         \n",
      "\n",
      "         \n",
      "\n",
      "         \n",
      "{\"id\":\"gen-1767176942-VZ0GCmWBeFjOed1P6meQ\",\"provider\":\"xAI\",\"model\":\"x-ai/grok-4.1-fast\",\"object\":\"chat.completion\",\"created\":1767176942,\"choices\":[{\"logprobs\":null,\"\n",
      "\n",
      "With reasoning parameter:\n",
      "  Status: 200\n",
      "  Response: \n",
      "         \n",
      "\n",
      "         \n",
      "\n",
      "         \n",
      "\n",
      "         \n",
      "\n",
      "         \n",
      "\n",
      "         \n",
      "\n",
      "         \n",
      "\n",
      "         \n",
      "{\"id\":\"gen-1767176944-0LNJdfYpbIVecGsliSZ4\",\"provider\":\"xAI\",\"model\":\"x-ai/grok-code-fast-1\",\"object\":\"chat.comp\n",
      "\n",
      "Phase 1 (grok-4.1-fast): ✓ Works\n",
      "Phase 2 (grok-code-fast-1): ✓ Works\n"
     ]
    }
   ],
   "source": [
    "# Test WITH reasoning parameter (like your actual code)\n",
    "def test_with_reasoning(model, api_key):\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    \n",
    "    payload_with_reasoning = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Say 'test'\"}],\n",
    "        \"max_tokens\": 100,\n",
    "        \"reasoning\": {\"enabled\": True}  # ← This is the problem\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=payload_with_reasoning)\n",
    "    print(f\"\\nWith reasoning parameter:\")\n",
    "    print(f\"  Status: {response.status_code}\")\n",
    "    print(f\"  Response: {response.text[:200]}\")\n",
    "    return response.status_code == 200\n",
    "\n",
    "# Test both models\n",
    "print(\"=\"*80)\n",
    "print(\"TESTING WITH REASONING PARAMETER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "phase1_works = test_with_reasoning(\"x-ai/grok-4.1-fast\", api_key)\n",
    "phase2_works = test_with_reasoning(\"x-ai/grok-code-fast-1\", api_key)\n",
    "\n",
    "print(f\"\\nPhase 1 (grok-4.1-fast): {'✓ Works' if phase1_works else '✗ Fails'}\")\n",
    "print(f\"Phase 2 (grok-code-fast-1): {'✓ Works' if phase2_works else '✗ Fails'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bfd2d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING FILES\n",
      "================================================================================\n",
      "✓ Loaded Phase 2B file (5514 chars)\n",
      "Preview:\n",
      "Task ID: 1ae2feb7 (Sample 0/3)\n",
      "================================================================================\n",
      "PHASE 2B: HYPOTHESIS VALIDATION\n",
      "================================================================================\n",
      "\n",
      "INITIAL HYPOTHESIS:\n",
      "--------------------------------------------------------------------------------\n",
      "In plain English, the transformation rule is:\n",
      "- Locate divider: unique full-height vertical bar of color 2 at col D.\n",
      "- Copy input left (0..D-1) & divider (D) unchanged to ou...\n",
      "\n",
      "✓ Loaded task 1ae2feb7\n",
      "  Train examples: 3\n",
      "  Test examples: 3\n",
      "\n",
      "================================================================================\n",
      "EXTRACTED VALIDATED PATTERN\n",
      "================================================================================\n",
      "**Final Pattern Description:**\n",
      "- Locate divider: unique (nearly) full-height vertical bar of *uniform non-zero color C* (not fixed to 2; e.g., C=2 in training, C=3 in test 1&2, C=4 in test 3) at col D. \"Full-height\" means identical C in every row of the grid (test 1/2/train) or nearly so, spanning all patterned rows even if bottom padding row(s) are 0 (test 3).\n",
      "- Copy input cols 0..D unchanged to output (including any 0s in divider col).\n",
      "- Initialize output right cols (D+1..end) to all 0 (ignores any input colors there).\n",
      "- For each row independently:\n",
      "  - In left cols 0..D-1 of that row, identify all maximal horizontal runs of *same non-zero color*.\n",
      "  - Sort/process these runs from right-to-left (rightmost first).\n",
      "  - For current run color=C_run, length=L: for rel pos p=0 to Wr-1 (Wr=width-D-1); if output_right[p] still 0 AND (p % L == 0), set to C_run.\n",
      "- Repeat leftward for next run (overlays only on remaining 0s). No left runs → right stays 0.\n",
      "\n",
      "Edge cases (all preserved/verified):\n",
      "- S\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PHASE 2C PROMPT BUILT\n",
      "================================================================================\n",
      "Content blocks: 47\n",
      "Total text length: 26056\n",
      "\n",
      "First block (first 300 chars):\n",
      "# DSL Code Generator\n",
      "Generate a Python `solve(I)` function using ONLY the DSL primitives below.\n",
      "\n",
      "\n",
      "\n",
      "Last block (first 300 chars):\n",
      "Generate the `solve(I)` function now.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SENDING REQUEST TO API\n",
      "================================================================================\n",
      "Model: x-ai/grok-4.1-fast\n",
      "API Base: https://openrouter.ai/api/v1\n",
      "Max Tokens: 32000\n",
      "Reasoning: {'reasoning': {'enabled': True}}\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "API RESPONSE RECEIVED\n",
      "================================================================================\n",
      "Time: 139.50s\n",
      "Response length: 569 chars\n",
      "\n",
      "First 1000 chars:\n",
      "```python\n",
      "def solve(I):\n",
      "    # Find rightmost column D with any non-background cell (divider column)\n",
      "    positions = asindices(I)\n",
      "    W = shape(I)[1]\n",
      "    col_has = [False] * W\n",
      "    for pos in positions:\n",
      "        col_has[pos[1]] = True\n",
      "    D = max((j for j in range(W) if col_has[j]), default=-1)  # safe max\n",
      "\n",
      "    # Grid dimensions\n",
      "    H = shape(I)[0]\n",
      "    Wr = W - D - 1\n",
      "\n",
      "    # Build output row by row\n",
      "    O_rows = []\n",
      "    for r in range(H):\n",
      "        # Extract input row\n",
      "        row_in = tuple(index(I, (r, j)) for j in range(W))\n",
      "        left = row_in[:D + 1]\n",
      "        pattern\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CODE EXTRACTION\n",
      "================================================================================\n",
      "✓ Code extracted successfully (559 chars)\n",
      "\n",
      "Extracted code:\n",
      "\n",
      "def solve(I):\n",
      "    # Find rightmost column D with any non-background cell (divider column)\n",
      "    positions = asindices(I)\n",
      "    W = shape(I)[1]\n",
      "    col_has = [False] * W\n",
      "    for pos in positions:\n",
      "        col_has[pos[1]] = True\n",
      "    D = max((j for j in range(W) if col_has[j]), default=-1)  # safe max\n",
      "\n",
      "    # Grid dimensions\n",
      "    H = shape(I)[0]\n",
      "    Wr = W - D - 1\n",
      "\n",
      "    # Build output row by row\n",
      "    O_rows = []\n",
      "    for r in range(H):\n",
      "        # Extract input row\n",
      "        row_in = tuple(index(I, (r, j)) for j in range(W))\n",
      "        left = row_in[:D + 1]\n",
      "        pattern\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Phase 2C Response Generation\n",
    "# Load a real Phase 2B file and generate Phase 2C response\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "# sys.path.append('../src')\n",
    "sys.path.insert(0, '/home/te0245/llms_ftw')\n",
    "\n",
    "from src.vlm_prompter import VLMPrompter\n",
    "from src.vlm_client import VLMConfig, create_client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "log_dir = \"../logs/grok4.1fast_grokcodefast1_reasoning_dsl_k4_80703\"\n",
    "task_id = \"1ae2feb7\"\n",
    "sample_idx = 0\n",
    "\n",
    "phase2b_file = f\"{log_dir}/{task_id}_sample{sample_idx}_phase2b_validation.txt\"\n",
    "task_file = f\"../data_v2/evaluation/{task_id}.json\"\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD FILES\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load Phase 2B validation\n",
    "with open(phase2b_file, 'r') as f:\n",
    "    phase2b_content = f.read()\n",
    "\n",
    "print(f\"✓ Loaded Phase 2B file ({len(phase2b_content)} chars)\")\n",
    "print(f\"Preview:\\n{phase2b_content[:500]}...\\n\")\n",
    "\n",
    "# Load task\n",
    "with open(task_file, 'r') as f:\n",
    "    task = json.load(f)\n",
    "\n",
    "print(f\"✓ Loaded task {task_id}\")\n",
    "print(f\"  Train examples: {len(task['train'])}\")\n",
    "print(f\"  Test examples: {len(task['test'])}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXTRACT VALIDATED PATTERN\n",
    "# ============================================================================\n",
    "import re\n",
    "\n",
    "def extract_validated_pattern_from_response(response: str) -> str:\n",
    "    \"\"\"Extract the validated pattern from phase 2b response.\"\"\"\n",
    "    pattern_match = re.search(r'<validated_pattern>(.*?)</validated_pattern>', \n",
    "                             response, re.DOTALL)\n",
    "    if pattern_match:\n",
    "        return pattern_match.group(1).strip()\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "validated_pattern = extract_validated_pattern_from_response(phase2b_content)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXTRACTED VALIDATED PATTERN\")\n",
    "print(\"=\"*80)\n",
    "print(validated_pattern[:1000])\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD PHASE 2C PROMPT\n",
    "# ============================================================================\n",
    "prompter = VLMPrompter()\n",
    "\n",
    "# Build prompt (DSL enabled, few-shot enabled, no similar programs for this test)\n",
    "phase2c_prompt = prompter.build_phase2c_prompt(\n",
    "    task=task,\n",
    "    validated_pattern=validated_pattern,\n",
    "    similar_programs=None,\n",
    "    few_shot=True,\n",
    "    dsl_enabled=True\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 2C PROMPT BUILT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Content blocks: {len(phase2c_prompt)}\")\n",
    "print(f\"Total text length: {sum(len(b['text']) for b in phase2c_prompt if b['type'] == 'text')}\")\n",
    "\n",
    "# Show first and last blocks\n",
    "print(f\"\\nFirst block (first 300 chars):\")\n",
    "print(phase2c_prompt[0]['text'][:300] if phase2c_prompt[0]['type'] == 'text' else phase2c_prompt[0])\n",
    "\n",
    "print(f\"\\nLast block (first 300 chars):\")\n",
    "last_block = phase2c_prompt[-1]\n",
    "print(last_block['text'][:300] if last_block['type'] == 'text' else last_block)\n",
    "\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE VLM CLIENT FOR PHASE 2\n",
    "# ============================================================================\n",
    "api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "vlm_config_phase2 = VLMConfig(\n",
    "    api_key=api_key,\n",
    "    model=\"x-ai/grok-4.1-fast\",\n",
    "    api_base=\"https://openrouter.ai/api/v1\",\n",
    "    max_tokens=32000,\n",
    "    max_retries=3,\n",
    "    extra_params={\n",
    "        'reasoning': {\n",
    "            'enabled': True\n",
    "        }\n",
    "    },\n",
    "    suppress_errors=False  # ← Don't suppress errors so we can see what fails\n",
    ")\n",
    "\n",
    "vlm_client_phase2 = create_client(\"grok\", config=vlm_config_phase2)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SENDING REQUEST TO API\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: {vlm_config_phase2.model}\")\n",
    "print(f\"API Base: {vlm_config_phase2.api_base}\")\n",
    "print(f\"Max Tokens: {vlm_config_phase2.max_tokens}\")\n",
    "print(f\"Reasoning: {vlm_config_phase2.extra_params}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# SEND REQUEST\n",
    "# ============================================================================\n",
    "import time\n",
    "\n",
    "system_prompt = \"\"\"You are an expert at generating code using the given DSL primitives to solve ARC puzzles. You are provided with a natural language description of the pattern to implement, as well as training and test examples and some similar programs you might find useful as reference. Generate a Python function `def solve(I):` that implements the described transformation using ONLY the provided DSL primitives. Ensure your code is syntactically correct and follows best practices.\"\"\"\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    response = vlm_client_phase2.query(phase2c_prompt, system_prompt)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"API RESPONSE RECEIVED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Time: {elapsed:.2f}s\")\n",
    "    print(f\"Response length: {len(response)} chars\")\n",
    "    print(f\"\\nFirst 1000 chars:\")\n",
    "    print(response[:1000])\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # EXTRACT CODE\n",
    "    # ============================================================================\n",
    "    def extract_code_from_response(response: str):\n",
    "        \"\"\"Extract Python code from LLM response.\"\"\"\n",
    "        python_blocks = re.findall(r'```python\\n(.*?)```', response, re.DOTALL)\n",
    "        \n",
    "        if python_blocks:\n",
    "            for block in python_blocks:\n",
    "                if 'def solve' in block:\n",
    "                    return block.strip()\n",
    "            return python_blocks[0].strip()\n",
    "        \n",
    "        match = re.search(r'(def solve\\(I\\):.*?)(?=\\n\\ndef|\\n\\nif __name__|$)', response, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    code = extract_code_from_response(response)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CODE EXTRACTION\")\n",
    "    print(\"=\"*80)\n",
    "    if code:\n",
    "        print(f\"✓ Code extracted successfully ({len(code)} chars)\")\n",
    "        print(f\"\\nExtracted code:\\n\")\n",
    "        print(code)\n",
    "    else:\n",
    "        print(\"✗ No code found in response\")\n",
    "        print(\"\\nSearching for 'def solve':\")\n",
    "        if 'def solve' in response:\n",
    "            print(\"  Found 'def solve' in response but extraction failed\")\n",
    "            idx = response.index('def solve')\n",
    "            print(f\"  Context around match:\\n{response[max(0,idx-100):idx+300]}\")\n",
    "        else:\n",
    "            print(\"  'def solve' not found in response at all\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"=\"*80)\n",
    "    print(\"ERROR OCCURRED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error message: {e}\")\n",
    "    \n",
    "    import traceback\n",
    "    print(\"\\nFull traceback:\")\n",
    "    traceback.print_exc()\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee531de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/te0245/llms_ftw/src'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e2d1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/te0245/miniconda3/lib/python313.zip',\n",
       " '/home/te0245/miniconda3/lib/python3.13',\n",
       " '/home/te0245/miniconda3/lib/python3.13/lib-dynload',\n",
       " '',\n",
       " '/home/te0245/miniconda3/lib/python3.13/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa605b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
